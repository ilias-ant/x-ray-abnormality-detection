{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a899787",
   "metadata": {},
   "source": [
    "## X-Ray Abnormality Detection | VGG19, pretrained on ImageNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7764e65",
   "metadata": {},
   "source": [
    "> **Antonopoulos Ilias** ( *p3352004* ) <br />\n",
    "> **Ndoja Silva** ( *p3352017* ) <br />\n",
    "> **MSc in Data Science, AUEB**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa71e65e",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "- [Data Loading](#Data-Loading)\n",
    " * [Create a tensorflow input pipeline for the training data](#Create-a-tensorflow-input-pipeline-for-the-training-data)\n",
    " * [Create a tensorflow input pipeline for the testing data](#Create-a-tensorflow-input-pipeline-for-the-testing-data)\n",
    "- [Baseline Performance](#Baseline-Performance)\n",
    " * [VGG19-architecture,-pretrained-on-ImageNet](#VGG19-architecture,-pretrained-on-ImageNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99fc7dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import pathlib\n",
    "import random\n",
    "import re\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "from typing import Iterable\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from matplotlib import image\n",
    "from sklearn.metrics import cohen_kappa_score, confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "pd.set_option(\"max_colwidth\", None)\n",
    "plt.style.use(\"dark_background\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d6c351a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fa8b39b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-27 14:38:06.127694: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-27 14:38:06.140180: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-27 14:38:06.140488: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices(\"GPU\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d64d949",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "\n",
    "try:\n",
    "    tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "except IndexError:\n",
    "    print(\"Cannot memory-restrict the GPU, if no GPU exists in system. Ignore...\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6659fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 99910123\n",
    "\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
    "random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5346f99",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5819c5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DIR = \"../data/MURA-v1.1/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22e69e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inspect_df(df: pd.DataFrame, n: int = 5) -> pd.DataFrame:\n",
    "    \"\"\"Helper method to easily inspect DataFrames.\"\"\"\n",
    "\n",
    "    print(f\"shape: {df.shape}\")\n",
    "\n",
    "    return df.head(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67d931da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/MURA-v1.1/train/XR_WRIST/patient08092/study1_negative/image1.png',\n",
       " '../data/MURA-v1.1/train/XR_FINGER/patient01064/study1_positive/image1.png',\n",
       " '../data/MURA-v1.1/valid/XR_ELBOW/patient11831/study1_positive/image1.png',\n",
       " '../data/MURA-v1.1/train/XR_SHOULDER/patient00442/study1_positive/image1.png',\n",
       " '../data/MURA-v1.1/train/XR_ELBOW/patient06289/study1_negative/image3.png',\n",
       " '../data/MURA-v1.1/train/XR_WRIST/patient08562/study1_negative/image2.png',\n",
       " '../data/MURA-v1.1/train/XR_FINGER/patient04280/study1_negative/image3.png',\n",
       " '../data/MURA-v1.1/train/XR_WRIST/patient07018/study1_positive/image1.png',\n",
       " '../data/MURA-v1.1/train/XR_ELBOW/patient06000/study1_negative/image1.png',\n",
       " '../data/MURA-v1.1/train/XR_SHOULDER/patient00497/study2_negative/image4.png']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choices(glob(os.path.join(DATASET_DIR, \"*\", \"*\", \"*\", \"*\", \"*.png\")), k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e68ad35",
   "metadata": {},
   "source": [
    "So, the data structure is the following:\n",
    "\n",
    "```\n",
    "\n",
    "└─train {data subset}\n",
    "│   └───XR_ELBOW {study type}\n",
    "│       │  └───patient00011 {patient}\n",
    "│       │         └───study1_negative {study with label}\n",
    "│       │               └───image1.png {view}\n",
    "│       │               └───image2.png \n",
    "│       │               └───image3.png \n",
    "                        └───...\n",
    "   ...\n",
    "   \n",
    "\n",
    "└─valid {data subset}\n",
    "│   └───XR_HUMERUS {study type}\n",
    "│       │  └───patient11216 {patient}\n",
    "│       │         └───study1_negative {study with label}\n",
    "│       │               └───image1.png {view}\n",
    "│       │               └───image2.png \n",
    "                        └───...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e99c8e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total PNG images found in dir <../data/MURA-v1.1/>: 40009\n"
     ]
    }
   ],
   "source": [
    "image_count = len(list(pathlib.Path(DATASET_DIR).glob(\"*/*/*/*/*.png\")))\n",
    "\n",
    "print(f\"Total PNG images found in dir <{DATASET_DIR}>: {image_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cc7391",
   "metadata": {},
   "source": [
    "We will start by creating a tabular form of the training data (with no actual image files), in order to quickly analyze them. A proper data loader (of the actual image files) will be implemented after that, in a tensorflow-friendly manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ee568f1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (36808, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MURA-v1.1/train/XR_SHOULDER/patient00001/study1_positive/image1.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MURA-v1.1/train/XR_SHOULDER/patient00001/study1_positive/image2.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MURA-v1.1/train/XR_SHOULDER/patient00001/study1_positive/image3.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MURA-v1.1/train/XR_SHOULDER/patient00002/study1_positive/image1.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MURA-v1.1/train/XR_SHOULDER/patient00002/study1_positive/image2.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                            image_path\n",
       "0  MURA-v1.1/train/XR_SHOULDER/patient00001/study1_positive/image1.png\n",
       "1  MURA-v1.1/train/XR_SHOULDER/patient00001/study1_positive/image2.png\n",
       "2  MURA-v1.1/train/XR_SHOULDER/patient00001/study1_positive/image3.png\n",
       "3  MURA-v1.1/train/XR_SHOULDER/patient00002/study1_positive/image1.png\n",
       "4  MURA-v1.1/train/XR_SHOULDER/patient00002/study1_positive/image2.png"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_image_paths = pd.read_csv(\n",
    "    os.path.join(DATASET_DIR, \"train_image_paths.csv\"),\n",
    "    names=[\"image_path\"],\n",
    "    header=None,\n",
    "    index_col=False,\n",
    ")\n",
    "\n",
    "inspect_df(train_image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60a69725",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_paths[\"image_path\"] = train_image_paths[\"image_path\"].map(\n",
    "    lambda x: os.path.join(\"../data/\", x)\n",
    ")\n",
    "train_image_paths[\"study_type\"] = train_image_paths[\"image_path\"].map(\n",
    "    lambda x: x.split(\"/\")[3]\n",
    ")\n",
    "train_image_paths[\"patient\"] = train_image_paths[\"image_path\"].map(\n",
    "    lambda x: x.split(\"/\")[4]\n",
    ")\n",
    "train_image_paths[\"study\"] = train_image_paths[\"image_path\"].map(\n",
    "    lambda x: x.split(\"/\")[5]\n",
    ")\n",
    "train_image_paths[\"study_path\"] = train_image_paths[\"image_path\"].map(\n",
    "    lambda x: re.sub(r\"image\\d+.png\", \"\", x)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d073e76e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (36808, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>study_type</th>\n",
       "      <th>patient</th>\n",
       "      <th>study</th>\n",
       "      <th>study_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../data/MURA-v1.1/train/XR_SHOULDER/patient00001/study1_positive/image1.png</td>\n",
       "      <td>train</td>\n",
       "      <td>XR_SHOULDER</td>\n",
       "      <td>patient00001</td>\n",
       "      <td>../data/MURA-v1.1/train/XR_SHOULDER/patient00001/study1_positive/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../data/MURA-v1.1/train/XR_SHOULDER/patient00001/study1_positive/image2.png</td>\n",
       "      <td>train</td>\n",
       "      <td>XR_SHOULDER</td>\n",
       "      <td>patient00001</td>\n",
       "      <td>../data/MURA-v1.1/train/XR_SHOULDER/patient00001/study1_positive/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../data/MURA-v1.1/train/XR_SHOULDER/patient00001/study1_positive/image3.png</td>\n",
       "      <td>train</td>\n",
       "      <td>XR_SHOULDER</td>\n",
       "      <td>patient00001</td>\n",
       "      <td>../data/MURA-v1.1/train/XR_SHOULDER/patient00001/study1_positive/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../data/MURA-v1.1/train/XR_SHOULDER/patient00002/study1_positive/image1.png</td>\n",
       "      <td>train</td>\n",
       "      <td>XR_SHOULDER</td>\n",
       "      <td>patient00002</td>\n",
       "      <td>../data/MURA-v1.1/train/XR_SHOULDER/patient00002/study1_positive/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../data/MURA-v1.1/train/XR_SHOULDER/patient00002/study1_positive/image2.png</td>\n",
       "      <td>train</td>\n",
       "      <td>XR_SHOULDER</td>\n",
       "      <td>patient00002</td>\n",
       "      <td>../data/MURA-v1.1/train/XR_SHOULDER/patient00002/study1_positive/</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                    image_path  \\\n",
       "0  ../data/MURA-v1.1/train/XR_SHOULDER/patient00001/study1_positive/image1.png   \n",
       "1  ../data/MURA-v1.1/train/XR_SHOULDER/patient00001/study1_positive/image2.png   \n",
       "2  ../data/MURA-v1.1/train/XR_SHOULDER/patient00001/study1_positive/image3.png   \n",
       "3  ../data/MURA-v1.1/train/XR_SHOULDER/patient00002/study1_positive/image1.png   \n",
       "4  ../data/MURA-v1.1/train/XR_SHOULDER/patient00002/study1_positive/image2.png   \n",
       "\n",
       "  study_type      patient         study  \\\n",
       "0      train  XR_SHOULDER  patient00001   \n",
       "1      train  XR_SHOULDER  patient00001   \n",
       "2      train  XR_SHOULDER  patient00001   \n",
       "3      train  XR_SHOULDER  patient00002   \n",
       "4      train  XR_SHOULDER  patient00002   \n",
       "\n",
       "                                                          study_path  \n",
       "0  ../data/MURA-v1.1/train/XR_SHOULDER/patient00001/study1_positive/  \n",
       "1  ../data/MURA-v1.1/train/XR_SHOULDER/patient00001/study1_positive/  \n",
       "2  ../data/MURA-v1.1/train/XR_SHOULDER/patient00001/study1_positive/  \n",
       "3  ../data/MURA-v1.1/train/XR_SHOULDER/patient00002/study1_positive/  \n",
       "4  ../data/MURA-v1.1/train/XR_SHOULDER/patient00002/study1_positive/  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inspect_df(train_image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "59cf2544",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (13457, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>study_path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MURA-v1.1/train/XR_SHOULDER/patient00001/study1_positive/</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MURA-v1.1/train/XR_SHOULDER/patient00002/study1_positive/</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MURA-v1.1/train/XR_SHOULDER/patient00003/study1_positive/</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MURA-v1.1/train/XR_SHOULDER/patient00004/study1_positive/</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MURA-v1.1/train/XR_SHOULDER/patient00005/study1_positive/</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  study_path  label\n",
       "0  MURA-v1.1/train/XR_SHOULDER/patient00001/study1_positive/      1\n",
       "1  MURA-v1.1/train/XR_SHOULDER/patient00002/study1_positive/      1\n",
       "2  MURA-v1.1/train/XR_SHOULDER/patient00003/study1_positive/      1\n",
       "3  MURA-v1.1/train/XR_SHOULDER/patient00004/study1_positive/      1\n",
       "4  MURA-v1.1/train/XR_SHOULDER/patient00005/study1_positive/      1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labeled_studies = pd.read_csv(\n",
    "    os.path.join(DATASET_DIR, \"train_labeled_studies.csv\"),\n",
    "    names=[\"study_path\", \"label\"],\n",
    "    header=None,\n",
    "    index_col=False,\n",
    ")\n",
    "\n",
    "inspect_df(train_labeled_studies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df9a7f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labeled_studies[\"study_path\"] = train_labeled_studies[\"study_path\"].map(\n",
    "    lambda x: os.path.join(\"../data/\", x)\n",
    ")\n",
    "train_labeled_studies[\"label\"] = train_labeled_studies[\"label\"].map(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "408b169b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (13457, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>study_path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../data/MURA-v1.1/train/XR_SHOULDER/patient00001/study1_positive/</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../data/MURA-v1.1/train/XR_SHOULDER/patient00002/study1_positive/</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../data/MURA-v1.1/train/XR_SHOULDER/patient00003/study1_positive/</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../data/MURA-v1.1/train/XR_SHOULDER/patient00004/study1_positive/</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../data/MURA-v1.1/train/XR_SHOULDER/patient00005/study1_positive/</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                          study_path label\n",
       "0  ../data/MURA-v1.1/train/XR_SHOULDER/patient00001/study1_positive/     1\n",
       "1  ../data/MURA-v1.1/train/XR_SHOULDER/patient00002/study1_positive/     1\n",
       "2  ../data/MURA-v1.1/train/XR_SHOULDER/patient00003/study1_positive/     1\n",
       "3  ../data/MURA-v1.1/train/XR_SHOULDER/patient00004/study1_positive/     1\n",
       "4  ../data/MURA-v1.1/train/XR_SHOULDER/patient00005/study1_positive/     1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inspect_df(train_labeled_studies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "98c49b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (36808, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>study_type</th>\n",
       "      <th>patient</th>\n",
       "      <th>study</th>\n",
       "      <th>study_path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../data/MURA-v1.1/train/XR_SHOULDER/patient00001/study1_positive/image1.png</td>\n",
       "      <td>train</td>\n",
       "      <td>XR_SHOULDER</td>\n",
       "      <td>patient00001</td>\n",
       "      <td>../data/MURA-v1.1/train/XR_SHOULDER/patient00001/study1_positive/</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../data/MURA-v1.1/train/XR_SHOULDER/patient00001/study1_positive/image2.png</td>\n",
       "      <td>train</td>\n",
       "      <td>XR_SHOULDER</td>\n",
       "      <td>patient00001</td>\n",
       "      <td>../data/MURA-v1.1/train/XR_SHOULDER/patient00001/study1_positive/</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../data/MURA-v1.1/train/XR_SHOULDER/patient00001/study1_positive/image3.png</td>\n",
       "      <td>train</td>\n",
       "      <td>XR_SHOULDER</td>\n",
       "      <td>patient00001</td>\n",
       "      <td>../data/MURA-v1.1/train/XR_SHOULDER/patient00001/study1_positive/</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../data/MURA-v1.1/train/XR_SHOULDER/patient00002/study1_positive/image1.png</td>\n",
       "      <td>train</td>\n",
       "      <td>XR_SHOULDER</td>\n",
       "      <td>patient00002</td>\n",
       "      <td>../data/MURA-v1.1/train/XR_SHOULDER/patient00002/study1_positive/</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../data/MURA-v1.1/train/XR_SHOULDER/patient00002/study1_positive/image2.png</td>\n",
       "      <td>train</td>\n",
       "      <td>XR_SHOULDER</td>\n",
       "      <td>patient00002</td>\n",
       "      <td>../data/MURA-v1.1/train/XR_SHOULDER/patient00002/study1_positive/</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                    image_path  \\\n",
       "0  ../data/MURA-v1.1/train/XR_SHOULDER/patient00001/study1_positive/image1.png   \n",
       "1  ../data/MURA-v1.1/train/XR_SHOULDER/patient00001/study1_positive/image2.png   \n",
       "2  ../data/MURA-v1.1/train/XR_SHOULDER/patient00001/study1_positive/image3.png   \n",
       "3  ../data/MURA-v1.1/train/XR_SHOULDER/patient00002/study1_positive/image1.png   \n",
       "4  ../data/MURA-v1.1/train/XR_SHOULDER/patient00002/study1_positive/image2.png   \n",
       "\n",
       "  study_type      patient         study  \\\n",
       "0      train  XR_SHOULDER  patient00001   \n",
       "1      train  XR_SHOULDER  patient00001   \n",
       "2      train  XR_SHOULDER  patient00001   \n",
       "3      train  XR_SHOULDER  patient00002   \n",
       "4      train  XR_SHOULDER  patient00002   \n",
       "\n",
       "                                                          study_path label  \n",
       "0  ../data/MURA-v1.1/train/XR_SHOULDER/patient00001/study1_positive/     1  \n",
       "1  ../data/MURA-v1.1/train/XR_SHOULDER/patient00001/study1_positive/     1  \n",
       "2  ../data/MURA-v1.1/train/XR_SHOULDER/patient00001/study1_positive/     1  \n",
       "3  ../data/MURA-v1.1/train/XR_SHOULDER/patient00002/study1_positive/     1  \n",
       "4  ../data/MURA-v1.1/train/XR_SHOULDER/patient00002/study1_positive/     1  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_trainset = pd.merge(\n",
    "    train_image_paths, train_labeled_studies, how=\"inner\", on=\"study_path\"\n",
    ")\n",
    "\n",
    "inspect_df(ref_trainset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41eafe23",
   "metadata": {},
   "source": [
    "#### Create a tensorflow input pipeline for the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "19f477b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_WIDTH = 224\n",
    "IMAGE_HEIGHT = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c8637a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "training = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rotation_range=30,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"constant\",\n",
    "    cval=0.0,\n",
    "    rescale=1.0 / 255,\n",
    "    validation_split=0.2,\n",
    "    preprocessing_function=tf.keras.applications.vgg19.preprocess_input,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "21f38eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29447 non-validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "trainset = training.flow_from_dataframe(\n",
    "    dataframe=ref_trainset,\n",
    "    x_col=\"image_path\",\n",
    "    y_col=\"label\",\n",
    "    target_size=(IMAGE_WIDTH, IMAGE_HEIGHT),\n",
    "    class_mode=\"binary\",\n",
    "    color_mode=\"rgb\",  # 3 channels\n",
    "    batch_size=16,\n",
    "    seed=SEED,\n",
    "    shuffle=True,\n",
    "    validate_filenames=False,\n",
    "    subset=\"training\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3d3baff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7361 non-validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "validationset = training.flow_from_dataframe(\n",
    "    dataframe=ref_trainset,\n",
    "    x_col=\"image_path\",\n",
    "    y_col=\"label\",\n",
    "    target_size=(IMAGE_WIDTH, IMAGE_HEIGHT),\n",
    "    class_mode=\"binary\",\n",
    "    color_mode=\"rgb\",  # 3 channels\n",
    "    batch_size=16,\n",
    "    seed=SEED,\n",
    "    shuffle=True,\n",
    "    validate_filenames=False,\n",
    "    subset=\"validation\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6384ad36",
   "metadata": {},
   "source": [
    "#### Create a tensorflow input pipeline for the testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "530cb791",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_paths = pd.read_csv(\n",
    "    os.path.join(DATASET_DIR, \"valid_image_paths.csv\"),\n",
    "    names=[\"image_path\"],\n",
    "    header=None,\n",
    "    index_col=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3c564c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_paths[\"image_path\"] = test_image_paths[\"image_path\"].map(\n",
    "    lambda x: os.path.join(\"../data/\", x)\n",
    ")\n",
    "test_image_paths[\"study_type\"] = test_image_paths[\"image_path\"].map(\n",
    "    lambda x: x.split(\"/\")[3]\n",
    ")\n",
    "test_image_paths[\"patient\"] = test_image_paths[\"image_path\"].map(\n",
    "    lambda x: x.split(\"/\")[4]\n",
    ")\n",
    "test_image_paths[\"study\"] = test_image_paths[\"image_path\"].map(\n",
    "    lambda x: x.split(\"/\")[5]\n",
    ")\n",
    "test_image_paths[\"study_path\"] = test_image_paths[\"image_path\"].map(\n",
    "    lambda x: re.sub(r\"image\\d+.png\", \"\", x)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "02fa25e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labeled_studies = pd.read_csv(\n",
    "    os.path.join(DATASET_DIR, \"valid_labeled_studies.csv\"),\n",
    "    names=[\"study_path\", \"label\"],\n",
    "    header=None,\n",
    "    index_col=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3b658d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labeled_studies[\"study_path\"] = test_labeled_studies[\"study_path\"].map(\n",
    "    lambda x: os.path.join(\"../data/\", x)\n",
    ")\n",
    "test_labeled_studies[\"label\"] = test_labeled_studies[\"label\"].map(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "28789518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (3197, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>study_type</th>\n",
       "      <th>patient</th>\n",
       "      <th>study</th>\n",
       "      <th>study_path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../data/MURA-v1.1/valid/XR_WRIST/patient11185/study1_positive/image1.png</td>\n",
       "      <td>valid</td>\n",
       "      <td>XR_WRIST</td>\n",
       "      <td>patient11185</td>\n",
       "      <td>../data/MURA-v1.1/valid/XR_WRIST/patient11185/study1_positive/</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../data/MURA-v1.1/valid/XR_WRIST/patient11185/study1_positive/image2.png</td>\n",
       "      <td>valid</td>\n",
       "      <td>XR_WRIST</td>\n",
       "      <td>patient11185</td>\n",
       "      <td>../data/MURA-v1.1/valid/XR_WRIST/patient11185/study1_positive/</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../data/MURA-v1.1/valid/XR_WRIST/patient11185/study1_positive/image3.png</td>\n",
       "      <td>valid</td>\n",
       "      <td>XR_WRIST</td>\n",
       "      <td>patient11185</td>\n",
       "      <td>../data/MURA-v1.1/valid/XR_WRIST/patient11185/study1_positive/</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../data/MURA-v1.1/valid/XR_WRIST/patient11185/study1_positive/image4.png</td>\n",
       "      <td>valid</td>\n",
       "      <td>XR_WRIST</td>\n",
       "      <td>patient11185</td>\n",
       "      <td>../data/MURA-v1.1/valid/XR_WRIST/patient11185/study1_positive/</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../data/MURA-v1.1/valid/XR_WRIST/patient11186/study1_positive/image1.png</td>\n",
       "      <td>valid</td>\n",
       "      <td>XR_WRIST</td>\n",
       "      <td>patient11186</td>\n",
       "      <td>../data/MURA-v1.1/valid/XR_WRIST/patient11186/study1_positive/</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                 image_path  \\\n",
       "0  ../data/MURA-v1.1/valid/XR_WRIST/patient11185/study1_positive/image1.png   \n",
       "1  ../data/MURA-v1.1/valid/XR_WRIST/patient11185/study1_positive/image2.png   \n",
       "2  ../data/MURA-v1.1/valid/XR_WRIST/patient11185/study1_positive/image3.png   \n",
       "3  ../data/MURA-v1.1/valid/XR_WRIST/patient11185/study1_positive/image4.png   \n",
       "4  ../data/MURA-v1.1/valid/XR_WRIST/patient11186/study1_positive/image1.png   \n",
       "\n",
       "  study_type   patient         study  \\\n",
       "0      valid  XR_WRIST  patient11185   \n",
       "1      valid  XR_WRIST  patient11185   \n",
       "2      valid  XR_WRIST  patient11185   \n",
       "3      valid  XR_WRIST  patient11185   \n",
       "4      valid  XR_WRIST  patient11186   \n",
       "\n",
       "                                                       study_path label  \n",
       "0  ../data/MURA-v1.1/valid/XR_WRIST/patient11185/study1_positive/     1  \n",
       "1  ../data/MURA-v1.1/valid/XR_WRIST/patient11185/study1_positive/     1  \n",
       "2  ../data/MURA-v1.1/valid/XR_WRIST/patient11185/study1_positive/     1  \n",
       "3  ../data/MURA-v1.1/valid/XR_WRIST/patient11185/study1_positive/     1  \n",
       "4  ../data/MURA-v1.1/valid/XR_WRIST/patient11186/study1_positive/     1  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_testset = pd.merge(\n",
    "    test_image_paths, test_labeled_studies, how=\"inner\", on=\"study_path\"\n",
    ")\n",
    "\n",
    "inspect_df(ref_testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7a83dfa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1.0 / 255,\n",
    "    preprocessing_function=tf.keras.applications.vgg19.preprocess_input,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c466ce62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3197 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "testset = testing.flow_from_dataframe(\n",
    "    dataframe=ref_testset,\n",
    "    x_col=\"image_path\",\n",
    "    y_col=\"label\",\n",
    "    target_size=(IMAGE_WIDTH, IMAGE_HEIGHT),\n",
    "    class_mode=\"binary\",\n",
    "    batch_size=16,\n",
    "    seed=SEED,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d182d1",
   "metadata": {},
   "source": [
    "### Baseline Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6de7e829",
   "metadata": {},
   "outputs": [],
   "source": [
    "def study_oriented_transformation(dataset: pd.DataFrame) -> Iterable:\n",
    "\n",
    "    for study, group in dataset.groupby(\"study_path\"):\n",
    "\n",
    "        study_label = group[\"label\"].values.take(0)\n",
    "        study_prediction = 1 if group[\"prediction\"].mean() > 0.5 else 0\n",
    "\n",
    "        yield study, study_label, study_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e2665b",
   "metadata": {},
   "source": [
    "#### VGG19 architecture, pretrained on ImageNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "53dda1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_up(model_):\n",
    "    tf.keras.backend.clear_session()\n",
    "    del model_\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "404f8518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the tfa.metrics.F1Score (https://www.tensorflow.org/addons/api_docs/python/tfa/metrics/F1Score)\n",
    "# requires some reshaping that is inconsistent with the other metrics we like to track\n",
    "# so we will define it from scratch\n",
    "\n",
    "\n",
    "class F1Score(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name=\"f1_score\", **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.f1 = self.add_weight(name=\"f1\", initializer=\"zeros\")\n",
    "        self.precision_fn = tf.keras.metrics.Precision()\n",
    "        self.recall_fn = tf.keras.metrics.Recall()\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        p = self.precision_fn(y_true, y_pred)\n",
    "        r = self.recall_fn(y_true, y_pred)\n",
    "        self.f1.assign(2 * ((p * r) / (p + r + 1e-10)))\n",
    "\n",
    "    def result(self):\n",
    "        return self.f1\n",
    "\n",
    "    def reset_state(self):\n",
    "        # we also need to reset the state of the precision and recall objects\n",
    "        self.precision_fn.reset_state()\n",
    "        self.recall_fn.reset_state()\n",
    "        self.f1.assign(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4e3a6125",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-27 14:38:08.051031: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-03-27 14:38:08.051942: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-27 14:38:08.052255: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-27 14:38:08.052466: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-27 14:38:09.039727: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-27 14:38:09.040005: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-27 14:38:09.040213: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-27 14:38:09.040380: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 200 MB memory:  -> device: 0, name: Quadro T1000, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "METRICS = [\n",
    "    tf.keras.metrics.TruePositives(name=\"tp\"),\n",
    "    tf.keras.metrics.FalsePositives(name=\"fp\"),\n",
    "    tf.keras.metrics.TrueNegatives(name=\"tn\"),\n",
    "    tf.keras.metrics.FalseNegatives(name=\"fn\"),\n",
    "    tf.keras.metrics.BinaryAccuracy(name=\"binary_acc\"),\n",
    "    tf.keras.metrics.Precision(name=\"precision\"),\n",
    "    tf.keras.metrics.Recall(name=\"recall\"),\n",
    "    F1Score(name=\"f1_score\"),\n",
    "    tf.keras.metrics.AUC(name=\"roc_auc\", curve=\"ROC\"),\n",
    "    tf.keras.metrics.AUC(name=\"pr_auc\", curve=\"PR\"),\n",
    "    tfa.metrics.CohenKappa(name=\"cohen_kappa\", num_classes=2),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4d269acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(\n",
    "    history: tf.keras.callbacks.History,\n",
    "    metrics: list = [\"loss\", \"cohen_kappa\", \"precision\", \"recall\"],\n",
    ") -> None:\n",
    "\n",
    "    plt.rcParams[\"figure.figsize\"] = (18, 15)\n",
    "\n",
    "    for n, metric in enumerate(metrics):\n",
    "        name = metric.replace(\"_\", \" \").capitalize()\n",
    "        plt.subplot(2, 2, n + 1)\n",
    "        plt.plot(\n",
    "            history.epoch, history.history[metric], linewidth=1.8, label=\"training\"\n",
    "        )\n",
    "        plt.plot(\n",
    "            history.epoch,\n",
    "            history.history[\"val_\" + metric],\n",
    "            linestyle=\"--\",\n",
    "            linewidth=1.8,\n",
    "            label=\"validation\",\n",
    "        )\n",
    "        plt.xlabel(\"epoch\")\n",
    "        plt.ylabel(name)\n",
    "        if metric == \"loss\":\n",
    "            plt.ylim([0, plt.ylim()[1]])\n",
    "        elif metric == \"cohen_kappa\":\n",
    "            plt.ylim([-1, 1])\n",
    "        else:\n",
    "            plt.ylim([0, 1])\n",
    "\n",
    "        plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "30921b05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "80142336/80134624 [==============================] - 23s 0us/step\n",
      "80150528/80134624 [==============================] - 23s 0us/step\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "VGG19 model from \n",
    "`\"Very Deep Convolutional Networks for Large-Scale Image Recognition\" <https://arxiv.org/abs/1409.1556>`_.\n",
    "\"\"\"\n",
    "vgg = tf.keras.applications.vgg19.VGG19(\n",
    "    include_top=False,  # do not include the fully-connected layer at the top of the network\n",
    "    weights=\"imagenet\",\n",
    "    input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, 3),\n",
    "    pooling=\"avg\",  # pooling mode for feature extraction\n",
    "    classes=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "202355bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_vgg_model(\n",
    "    base_model: tf.keras.applications.vgg19.VGG19,\n",
    ") -> tf.keras.Model:\n",
    "\n",
    "    # freeze base model\n",
    "    base_model.trainable = False\n",
    "\n",
    "    inputs = tf.keras.Input(shape=(IMAGE_WIDTH, IMAGE_HEIGHT, 3))\n",
    "    # the base model contains batchnorm layer - we want to keep them in inference mode\n",
    "    # when we unfreeze the base model for fine-tuning, so we make sure that the\n",
    "    # base model is running in inference mode here.\n",
    "    x = base_model(inputs, training=False)\n",
    "    x = tf.keras.layers.Dropout(rate=0.2)(x)\n",
    "    output = tf.keras.layers.Dense(units=1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs, output)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "        loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "        metrics=METRICS,\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b2e68f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_vgg_model(base_model=vgg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1c19ad13",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " vgg19 (Functional)          (None, 512)               20024384  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,024,897\n",
      "Trainable params: 513\n",
      "Non-trainable params: 20,024,384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "97981226",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(\n",
    "    model,\n",
    "    to_file=\"../static/vgg19_pt_imagenet-all-study-types-20024897.png\",\n",
    "    show_shapes=True,\n",
    "    show_layer_names=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "571221da",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_cohen_kappa\",\n",
    "    verbose=1,\n",
    "    patience=5,\n",
    "    mode=\"max\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "16cd65d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr_on_plateau = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor=\"val_cohen_kappa\", factor=0.2, verbose=1, patience=7, min_lr=1e-10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa319ec8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    trainset,\n",
    "    epochs=20,\n",
    "    validation_data=validationset,\n",
    "    callbacks=[early_stopping, reduce_lr_on_plateau],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4fda3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ab3e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model naming convention: {architecture}-{which-study-type?}-{num-parameters}.h5\n",
    "#\n",
    "# to load models:\n",
    "# model = tf.keras.models.load_model(\n",
    "#     '../models/vgg19_pt_imagenet-all-study-types-20024897.h5',\n",
    "#     custom_objects={'F1Score': F1Score}\n",
    "# )\n",
    "# vgg = tf.keras.models.load_model(\n",
    "#     '../models/vgg19_base.h5',\n",
    "# )\n",
    "model.save(\"../models/vgg19_pt_imagenet-all-study-types-20024897.h5\")\n",
    "vgg.save(\"../models/vgg19_base.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ecc66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fine-tuning: unfreeze the base model and train the entire model end-to-end with a low learning rate\n",
    "vgg.trainable = True\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-5),\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    metrics=METRICS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e36539b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    trainset,\n",
    "    epochs=10,\n",
    "    validation_data=validationset,\n",
    "    callbacks=[early_stopping, reduce_lr_on_plateau],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b3e659",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# get the loss value & metrics values for the model in test mode\n",
    "evaluation_metrics = model.evaluate(testset, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dde6265",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = evaluation_metrics.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fab3d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"EVALUATION ON TEST DATASET\")\n",
    "print(\"=\" * 32)\n",
    "print(f\"loss        : {loss}\")\n",
    "for metric, score in zip(METRICS, evaluation_metrics):\n",
    "\n",
    "    print(f\"{metric.name + ' ' * (12 - len(metric.name))}: {score}\")\n",
    "print(\"=\" * 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af0810e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predictions for the test dataset\n",
    "preds = model.predict(testset, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a425738d",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_testset = ref_testset.copy()\n",
    "\n",
    "temp_testset[\"label\"] = temp_testset[\"label\"].map(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7846413c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cohen_kappa_score(\n",
    "    y1=temp_testset[\"label\"].values,\n",
    "    y2=np.vectorize(lambda x: 1 if x > 0.5 else 0)(preds.ravel()),\n",
    "    labels=[0, 1],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54151ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    classification_report(\n",
    "        temp_testset[\"label\"].values,\n",
    "        np.vectorize(lambda x: 1 if x > 0.5 else 0)(preds.ravel()),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1306b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_testset[\"prediction\"] = preds.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7620629",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_testset = pd.DataFrame(\n",
    "    [*study_oriented_transformation(temp_testset)],\n",
    "    columns=[\"study\", \"label\", \"prediction\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ed6666",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cohen_kappa_score(\n",
    "    y1=temp_testset[\"label\"].values, y2=temp_testset[\"prediction\"].values, labels=[0, 1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816fae38",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    classification_report(\n",
    "        temp_testset[\"label\"].values,\n",
    "        temp_testset[\"prediction\"].values,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9491c46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_up(model)\n",
    "clean_up(vgg)\n",
    "del temp_testset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
