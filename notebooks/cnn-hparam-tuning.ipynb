{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a899787",
   "metadata": {},
   "source": [
    "## X-Ray Abnormality Detection | CNN: Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7764e65",
   "metadata": {},
   "source": [
    "> **Antonopoulos Ilias** ( *p3352004* ) <br />\n",
    "> **Ndoja Silva** ( *p3352017* ) <br />\n",
    "> **MSc in Data Science, AUEB**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa71e65e",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "- [Data Loading](#Data-Loading)\n",
    " * [Create a tensorflow input pipeline for the training data](#Create-a-tensorflow-input-pipeline-for-the-training-data)\n",
    "- [CNN: Hyperparameter Tuning](#CNN:-Hyperparameter-Tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99fc7dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import random\n",
    "import re\n",
    "from glob import glob\n",
    "\n",
    "import keras_tuner as kt\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from utils import (\n",
    "    clean_up,\n",
    "    F1Score,\n",
    "    inspect_df,\n",
    "    plot_metrics,\n",
    ")\n",
    "\n",
    "pd.set_option(\"max_colwidth\", None)\n",
    "plt.style.use(\"dark_background\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d6c351a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fa8b39b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-02 22:36:20.279377: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-02 22:36:20.286864: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-02 22:36:20.287038: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices(\"GPU\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d64d949",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "\n",
    "try:\n",
    "    tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "except IndexError:\n",
    "    print(\"Cannot memory-restrict the GPU, if no GPU exists in system. Ignore...\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6659fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 99910123\n",
    "\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
    "random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5346f99",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5819c5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DIR = \"../data/MURA-v1.1/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67d931da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/MURA-v1.1/train/XR_WRIST/patient08092/study1_negative/image1.png',\n",
       " '../data/MURA-v1.1/train/XR_FINGER/patient01064/study1_positive/image1.png',\n",
       " '../data/MURA-v1.1/valid/XR_ELBOW/patient11831/study1_positive/image1.png',\n",
       " '../data/MURA-v1.1/train/XR_SHOULDER/patient00442/study1_positive/image1.png',\n",
       " '../data/MURA-v1.1/train/XR_ELBOW/patient06289/study1_negative/image3.png',\n",
       " '../data/MURA-v1.1/train/XR_WRIST/patient08562/study1_negative/image2.png',\n",
       " '../data/MURA-v1.1/train/XR_FINGER/patient04280/study1_negative/image3.png',\n",
       " '../data/MURA-v1.1/train/XR_WRIST/patient07018/study1_positive/image1.png',\n",
       " '../data/MURA-v1.1/train/XR_ELBOW/patient06000/study1_negative/image1.png',\n",
       " '../data/MURA-v1.1/train/XR_SHOULDER/patient00497/study2_negative/image4.png']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choices(glob(os.path.join(DATASET_DIR, \"*\", \"*\", \"*\", \"*\", \"*.png\")), k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e68ad35",
   "metadata": {},
   "source": [
    "So, the data structure is the following:\n",
    "\n",
    "```\n",
    "\n",
    "└─train {data subset}\n",
    "│   └───XR_ELBOW {study type}\n",
    "│       │  └───patient00011 {patient}\n",
    "│       │         └───study1_negative {study with label}\n",
    "│       │               └───image1.png {view}\n",
    "│       │               └───image2.png \n",
    "│       │               └───image3.png \n",
    "                        └───...\n",
    "   ...\n",
    "   \n",
    "\n",
    "└─valid {data subset}\n",
    "│   └───XR_HUMERUS {study type}\n",
    "│       │  └───patient11216 {patient}\n",
    "│       │         └───study1_negative {study with label}\n",
    "│       │               └───image1.png {view}\n",
    "│       │               └───image2.png \n",
    "                        └───...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e99c8e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total PNG images found in dir <../data/MURA-v1.1/>: 40009\n"
     ]
    }
   ],
   "source": [
    "image_count = len(list(pathlib.Path(DATASET_DIR).glob(\"*/*/*/*/*.png\")))\n",
    "\n",
    "print(f\"Total PNG images found in dir <{DATASET_DIR}>: {image_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cc7391",
   "metadata": {},
   "source": [
    "We will start by creating a tabular form of the training data (with no actual image files), in order to quickly analyze them. A proper data loader (of the actual image files) will be implemented after that, in a tensorflow-friendly manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ee568f1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (36808, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MURA-v1.1/train/XR_SHOULDER/patient00001/study1_positive/image1.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MURA-v1.1/train/XR_SHOULDER/patient00001/study1_positive/image2.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MURA-v1.1/train/XR_SHOULDER/patient00001/study1_positive/image3.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MURA-v1.1/train/XR_SHOULDER/patient00002/study1_positive/image1.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MURA-v1.1/train/XR_SHOULDER/patient00002/study1_positive/image2.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                            image_path\n",
       "0  MURA-v1.1/train/XR_SHOULDER/patient00001/study1_positive/image1.png\n",
       "1  MURA-v1.1/train/XR_SHOULDER/patient00001/study1_positive/image2.png\n",
       "2  MURA-v1.1/train/XR_SHOULDER/patient00001/study1_positive/image3.png\n",
       "3  MURA-v1.1/train/XR_SHOULDER/patient00002/study1_positive/image1.png\n",
       "4  MURA-v1.1/train/XR_SHOULDER/patient00002/study1_positive/image2.png"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_image_paths = pd.read_csv(\n",
    "    os.path.join(DATASET_DIR, \"train_image_paths.csv\"),\n",
    "    names=[\"image_path\"],\n",
    "    header=None,\n",
    "    index_col=False,\n",
    ")\n",
    "\n",
    "inspect_df(train_image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60a69725",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_paths[\"image_path\"] = train_image_paths[\"image_path\"].map(\n",
    "    lambda x: os.path.join(\"../data/\", x)\n",
    ")\n",
    "train_image_paths[\"study_type\"] = train_image_paths[\"image_path\"].map(\n",
    "    lambda x: x.split(\"/\")[4]\n",
    ")\n",
    "train_image_paths[\"patient\"] = train_image_paths[\"image_path\"].map(\n",
    "    lambda x: x.split(\"/\")[5]\n",
    ")\n",
    "train_image_paths[\"study\"] = train_image_paths[\"image_path\"].map(\n",
    "    lambda x: x.split(\"/\")[6]\n",
    ")\n",
    "train_image_paths[\"study_path\"] = train_image_paths[\"image_path\"].map(\n",
    "    lambda x: re.sub(r\"image\\d+.png\", \"\", x)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d073e76e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (36808, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>study_type</th>\n",
       "      <th>patient</th>\n",
       "      <th>study</th>\n",
       "      <th>study_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../data/MURA-v1.1/train/XR_SHOULDER/patient00001/study1_positive/image1.png</td>\n",
       "      <td>XR_SHOULDER</td>\n",
       "      <td>patient00001</td>\n",
       "      <td>study1_positive</td>\n",
       "      <td>../data/MURA-v1.1/train/XR_SHOULDER/patient00001/study1_positive/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../data/MURA-v1.1/train/XR_SHOULDER/patient00001/study1_positive/image2.png</td>\n",
       "      <td>XR_SHOULDER</td>\n",
       "      <td>patient00001</td>\n",
       "      <td>study1_positive</td>\n",
       "      <td>../data/MURA-v1.1/train/XR_SHOULDER/patient00001/study1_positive/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../data/MURA-v1.1/train/XR_SHOULDER/patient00001/study1_positive/image3.png</td>\n",
       "      <td>XR_SHOULDER</td>\n",
       "      <td>patient00001</td>\n",
       "      <td>study1_positive</td>\n",
       "      <td>../data/MURA-v1.1/train/XR_SHOULDER/patient00001/study1_positive/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../data/MURA-v1.1/train/XR_SHOULDER/patient00002/study1_positive/image1.png</td>\n",
       "      <td>XR_SHOULDER</td>\n",
       "      <td>patient00002</td>\n",
       "      <td>study1_positive</td>\n",
       "      <td>../data/MURA-v1.1/train/XR_SHOULDER/patient00002/study1_positive/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../data/MURA-v1.1/train/XR_SHOULDER/patient00002/study1_positive/image2.png</td>\n",
       "      <td>XR_SHOULDER</td>\n",
       "      <td>patient00002</td>\n",
       "      <td>study1_positive</td>\n",
       "      <td>../data/MURA-v1.1/train/XR_SHOULDER/patient00002/study1_positive/</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                    image_path  \\\n",
       "0  ../data/MURA-v1.1/train/XR_SHOULDER/patient00001/study1_positive/image1.png   \n",
       "1  ../data/MURA-v1.1/train/XR_SHOULDER/patient00001/study1_positive/image2.png   \n",
       "2  ../data/MURA-v1.1/train/XR_SHOULDER/patient00001/study1_positive/image3.png   \n",
       "3  ../data/MURA-v1.1/train/XR_SHOULDER/patient00002/study1_positive/image1.png   \n",
       "4  ../data/MURA-v1.1/train/XR_SHOULDER/patient00002/study1_positive/image2.png   \n",
       "\n",
       "    study_type       patient            study  \\\n",
       "0  XR_SHOULDER  patient00001  study1_positive   \n",
       "1  XR_SHOULDER  patient00001  study1_positive   \n",
       "2  XR_SHOULDER  patient00001  study1_positive   \n",
       "3  XR_SHOULDER  patient00002  study1_positive   \n",
       "4  XR_SHOULDER  patient00002  study1_positive   \n",
       "\n",
       "                                                          study_path  \n",
       "0  ../data/MURA-v1.1/train/XR_SHOULDER/patient00001/study1_positive/  \n",
       "1  ../data/MURA-v1.1/train/XR_SHOULDER/patient00001/study1_positive/  \n",
       "2  ../data/MURA-v1.1/train/XR_SHOULDER/patient00001/study1_positive/  \n",
       "3  ../data/MURA-v1.1/train/XR_SHOULDER/patient00002/study1_positive/  \n",
       "4  ../data/MURA-v1.1/train/XR_SHOULDER/patient00002/study1_positive/  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inspect_df(train_image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "59cf2544",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (13457, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>study_path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MURA-v1.1/train/XR_SHOULDER/patient00001/study1_positive/</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MURA-v1.1/train/XR_SHOULDER/patient00002/study1_positive/</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MURA-v1.1/train/XR_SHOULDER/patient00003/study1_positive/</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MURA-v1.1/train/XR_SHOULDER/patient00004/study1_positive/</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MURA-v1.1/train/XR_SHOULDER/patient00005/study1_positive/</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  study_path  label\n",
       "0  MURA-v1.1/train/XR_SHOULDER/patient00001/study1_positive/      1\n",
       "1  MURA-v1.1/train/XR_SHOULDER/patient00002/study1_positive/      1\n",
       "2  MURA-v1.1/train/XR_SHOULDER/patient00003/study1_positive/      1\n",
       "3  MURA-v1.1/train/XR_SHOULDER/patient00004/study1_positive/      1\n",
       "4  MURA-v1.1/train/XR_SHOULDER/patient00005/study1_positive/      1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labeled_studies = pd.read_csv(\n",
    "    os.path.join(DATASET_DIR, \"train_labeled_studies.csv\"),\n",
    "    names=[\"study_path\", \"label\"],\n",
    "    header=None,\n",
    "    index_col=False,\n",
    ")\n",
    "\n",
    "inspect_df(train_labeled_studies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df9a7f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labeled_studies[\"study_path\"] = train_labeled_studies[\"study_path\"].map(\n",
    "    lambda x: os.path.join(\"../data/\", x)\n",
    ")\n",
    "train_labeled_studies[\"label\"] = train_labeled_studies[\"label\"].map(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "408b169b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (13457, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>study_path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../data/MURA-v1.1/train/XR_SHOULDER/patient00001/study1_positive/</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../data/MURA-v1.1/train/XR_SHOULDER/patient00002/study1_positive/</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../data/MURA-v1.1/train/XR_SHOULDER/patient00003/study1_positive/</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../data/MURA-v1.1/train/XR_SHOULDER/patient00004/study1_positive/</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../data/MURA-v1.1/train/XR_SHOULDER/patient00005/study1_positive/</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                          study_path label\n",
       "0  ../data/MURA-v1.1/train/XR_SHOULDER/patient00001/study1_positive/     1\n",
       "1  ../data/MURA-v1.1/train/XR_SHOULDER/patient00002/study1_positive/     1\n",
       "2  ../data/MURA-v1.1/train/XR_SHOULDER/patient00003/study1_positive/     1\n",
       "3  ../data/MURA-v1.1/train/XR_SHOULDER/patient00004/study1_positive/     1\n",
       "4  ../data/MURA-v1.1/train/XR_SHOULDER/patient00005/study1_positive/     1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inspect_df(train_labeled_studies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "98c49b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (36808, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>study_type</th>\n",
       "      <th>patient</th>\n",
       "      <th>study</th>\n",
       "      <th>study_path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../data/MURA-v1.1/train/XR_SHOULDER/patient00001/study1_positive/image1.png</td>\n",
       "      <td>XR_SHOULDER</td>\n",
       "      <td>patient00001</td>\n",
       "      <td>study1_positive</td>\n",
       "      <td>../data/MURA-v1.1/train/XR_SHOULDER/patient00001/study1_positive/</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../data/MURA-v1.1/train/XR_SHOULDER/patient00001/study1_positive/image2.png</td>\n",
       "      <td>XR_SHOULDER</td>\n",
       "      <td>patient00001</td>\n",
       "      <td>study1_positive</td>\n",
       "      <td>../data/MURA-v1.1/train/XR_SHOULDER/patient00001/study1_positive/</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../data/MURA-v1.1/train/XR_SHOULDER/patient00001/study1_positive/image3.png</td>\n",
       "      <td>XR_SHOULDER</td>\n",
       "      <td>patient00001</td>\n",
       "      <td>study1_positive</td>\n",
       "      <td>../data/MURA-v1.1/train/XR_SHOULDER/patient00001/study1_positive/</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../data/MURA-v1.1/train/XR_SHOULDER/patient00002/study1_positive/image1.png</td>\n",
       "      <td>XR_SHOULDER</td>\n",
       "      <td>patient00002</td>\n",
       "      <td>study1_positive</td>\n",
       "      <td>../data/MURA-v1.1/train/XR_SHOULDER/patient00002/study1_positive/</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../data/MURA-v1.1/train/XR_SHOULDER/patient00002/study1_positive/image2.png</td>\n",
       "      <td>XR_SHOULDER</td>\n",
       "      <td>patient00002</td>\n",
       "      <td>study1_positive</td>\n",
       "      <td>../data/MURA-v1.1/train/XR_SHOULDER/patient00002/study1_positive/</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                    image_path  \\\n",
       "0  ../data/MURA-v1.1/train/XR_SHOULDER/patient00001/study1_positive/image1.png   \n",
       "1  ../data/MURA-v1.1/train/XR_SHOULDER/patient00001/study1_positive/image2.png   \n",
       "2  ../data/MURA-v1.1/train/XR_SHOULDER/patient00001/study1_positive/image3.png   \n",
       "3  ../data/MURA-v1.1/train/XR_SHOULDER/patient00002/study1_positive/image1.png   \n",
       "4  ../data/MURA-v1.1/train/XR_SHOULDER/patient00002/study1_positive/image2.png   \n",
       "\n",
       "    study_type       patient            study  \\\n",
       "0  XR_SHOULDER  patient00001  study1_positive   \n",
       "1  XR_SHOULDER  patient00001  study1_positive   \n",
       "2  XR_SHOULDER  patient00001  study1_positive   \n",
       "3  XR_SHOULDER  patient00002  study1_positive   \n",
       "4  XR_SHOULDER  patient00002  study1_positive   \n",
       "\n",
       "                                                          study_path label  \n",
       "0  ../data/MURA-v1.1/train/XR_SHOULDER/patient00001/study1_positive/     1  \n",
       "1  ../data/MURA-v1.1/train/XR_SHOULDER/patient00001/study1_positive/     1  \n",
       "2  ../data/MURA-v1.1/train/XR_SHOULDER/patient00001/study1_positive/     1  \n",
       "3  ../data/MURA-v1.1/train/XR_SHOULDER/patient00002/study1_positive/     1  \n",
       "4  ../data/MURA-v1.1/train/XR_SHOULDER/patient00002/study1_positive/     1  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_trainset = pd.merge(\n",
    "    train_image_paths, train_labeled_studies, how=\"inner\", on=\"study_path\"\n",
    ")\n",
    "\n",
    "inspect_df(ref_trainset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41eafe23",
   "metadata": {},
   "source": [
    "#### Create a tensorflow input pipeline for the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "19f477b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_WIDTH = 224\n",
    "IMAGE_HEIGHT = 224"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7b5630",
   "metadata": {},
   "source": [
    "Since image directory follows a specific ontological structure (7 upper extremities aka study types) we will shuffle the training dataset beforehand in order to ensure that the validation set will be representable of all study types. \n",
    "\n",
    "This is due to the fact that tf.keras `tf.keras.preprocessing.image.ImageDataGenerator` first performs the train-val split and then shuffles per epoch by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f2d8f562",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_trainset = shuffle(ref_trainset, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c8637a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "training = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rotation_range=30,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"constant\",\n",
    "    cval=0.0,\n",
    "    rescale=1.0 / 255,\n",
    "    validation_split=0.25,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "21f38eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 27606 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "trainset = training.flow_from_dataframe(\n",
    "    dataframe=ref_trainset,\n",
    "    x_col=\"image_path\",\n",
    "    y_col=\"label\",\n",
    "    target_size=(IMAGE_WIDTH, IMAGE_HEIGHT),\n",
    "    class_mode=\"binary\",\n",
    "    batch_size=32,\n",
    "    seed=SEED,\n",
    "    shuffle=True,\n",
    "    subset=\"training\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3d3baff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9202 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "validationset = training.flow_from_dataframe(\n",
    "    dataframe=ref_trainset,\n",
    "    x_col=\"image_path\",\n",
    "    y_col=\"label\",\n",
    "    target_size=(IMAGE_WIDTH, IMAGE_HEIGHT),\n",
    "    class_mode=\"binary\",\n",
    "    batch_size=32,\n",
    "    seed=SEED,\n",
    "    shuffle=True,\n",
    "    subset=\"validation\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e2665b",
   "metadata": {},
   "source": [
    "### CNN: Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4e3a6125",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-02 22:36:21.682048: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-02 22:36:21.683300: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-02 22:36:21.683558: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-02 22:36:21.683774: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-02 22:36:22.083255: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-02 22:36:22.083461: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-02 22:36:22.083586: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-02 22:36:22.083693: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2121 MB memory:  -> device: 0, name: Quadro T1000, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "METRICS = [\n",
    "    tf.keras.metrics.TruePositives(name=\"tp\"),\n",
    "    tf.keras.metrics.FalsePositives(name=\"fp\"),\n",
    "    tf.keras.metrics.TrueNegatives(name=\"tn\"),\n",
    "    tf.keras.metrics.FalseNegatives(name=\"fn\"),\n",
    "    tf.keras.metrics.BinaryAccuracy(name=\"binary_acc\"),\n",
    "    tf.keras.metrics.Precision(name=\"precision\"),\n",
    "    tf.keras.metrics.Recall(name=\"recall\"),\n",
    "    F1Score(name=\"f1_score\"),\n",
    "    tf.keras.metrics.AUC(name=\"roc_auc\", curve=\"ROC\"),\n",
    "    tf.keras.metrics.AUC(name=\"pr_auc\", curve=\"PR\"),\n",
    "    tfa.metrics.CohenKappa(name=\"cohen_kappa\", num_classes=2),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "202355bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model_builder(hp):\n",
    "    \"\"\"Creates a HyperModel instance (or callable that takes hyperparameters and returns a Model instance).\"\"\"\n",
    "\n",
    "    dropout_rate = hp.Float(\"dropout\", min_value=0.1, max_value=0.4, step=0.1)\n",
    "\n",
    "    model = tf.keras.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.Conv2D(\n",
    "                filters=16,\n",
    "                kernel_size=(3, 3),\n",
    "                strides=(1, 1),\n",
    "                padding=\"same\",\n",
    "                kernel_regularizer=\"l2\",\n",
    "                dilation_rate=(1, 1),\n",
    "                activation=\"relu\",\n",
    "                input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, 3),\n",
    "                name=\"1st-convolution\",\n",
    "            ),\n",
    "            tf.keras.layers.BatchNormalization(name=\"1st-batch-norm\"),\n",
    "            tf.keras.layers.MaxPool2D(\n",
    "                pool_size=(2, 2), strides=(2, 2), padding=\"same\", name=\"1st-max-pooling\"\n",
    "            ),\n",
    "            tf.keras.layers.Dropout(\n",
    "                rate=dropout_rate,\n",
    "                name=\"1st-dropout\",\n",
    "            ),\n",
    "            tf.keras.layers.Conv2D(\n",
    "                filters=32,\n",
    "                kernel_size=(3, 3),\n",
    "                strides=(1, 1),\n",
    "                padding=\"same\",\n",
    "                kernel_regularizer=\"l2\",\n",
    "                dilation_rate=(1, 1),\n",
    "                activation=\"relu\",\n",
    "                name=\"2nd-convolution\",\n",
    "            ),\n",
    "            tf.keras.layers.BatchNormalization(name=\"2nd-batch-norm\"),\n",
    "            tf.keras.layers.MaxPool2D(\n",
    "                pool_size=(2, 2), strides=(2, 2), padding=\"same\", name=\"2nd-max-pooling\"\n",
    "            ),\n",
    "            tf.keras.layers.Dropout(\n",
    "                rate=dropout_rate,\n",
    "                name=\"2nd-dropout\",\n",
    "            ),\n",
    "            tf.keras.layers.Conv2D(\n",
    "                filters=64,\n",
    "                kernel_size=(3, 3),\n",
    "                strides=(1, 1),\n",
    "                padding=\"same\",\n",
    "                kernel_regularizer=\"l2\",\n",
    "                dilation_rate=(1, 1),\n",
    "                activation=\"relu\",\n",
    "                name=\"3rd-convolution\",\n",
    "            ),\n",
    "            tf.keras.layers.BatchNormalization(name=\"3rd-batch-norm\"),\n",
    "            tf.keras.layers.MaxPool2D(\n",
    "                pool_size=(2, 2), strides=(2, 2), padding=\"same\", name=\"3rd-max-pooling\"\n",
    "            ),\n",
    "            tf.keras.layers.Dropout(\n",
    "                rate=dropout_rate,\n",
    "                name=\"3rd-dropout\",\n",
    "            ),\n",
    "            tf.keras.layers.Conv2D(\n",
    "                filters=128,\n",
    "                kernel_size=(3, 3),\n",
    "                strides=(1, 1),\n",
    "                padding=\"same\",\n",
    "                kernel_regularizer=\"l2\",\n",
    "                dilation_rate=(1, 1),\n",
    "                activation=\"relu\",\n",
    "                input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, 3),\n",
    "                name=\"4th-convolution\",\n",
    "            ),\n",
    "            tf.keras.layers.BatchNormalization(name=\"4th-batch-norm\"),\n",
    "            tf.keras.layers.MaxPool2D(\n",
    "                pool_size=(2, 2), strides=(2, 2), padding=\"same\", name=\"4th-max-pooling\"\n",
    "            ),\n",
    "            tf.keras.layers.Dropout(\n",
    "                rate=dropout_rate,\n",
    "                name=\"4th-dropout\",\n",
    "            ),\n",
    "            tf.keras.layers.Flatten(name=\"flatten-layer\"),\n",
    "            tf.keras.layers.Dense(\n",
    "                units=hp.Int(\"dense-layer-units\", min_value=32, max_value=128, step=32),\n",
    "                kernel_regularizer=\"l2\",\n",
    "                activation=\"relu\",\n",
    "                name=\"dense-layer\",\n",
    "            ),\n",
    "            tf.keras.layers.Dense(units=1, activation=\"sigmoid\", name=\"output-layer\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(\n",
    "            learning_rate=hp.Choice(\n",
    "                \"learning-rate\", values=[1e-4, 2 * 1e-4, 3 * 1e-4, 4 * 1e-4, 5 * 1e-4]\n",
    "            )\n",
    "        ),\n",
    "        loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "        metrics=METRICS,\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fd77df18",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tuner = kt.BayesianOptimization(\n",
    "    cnn_model_builder,\n",
    "    objective=kt.Objective(\"val_cohen_kappa\", \"max\"),\n",
    "    max_trials=12,  # the total number of trials (model configurations) to test at most\n",
    "    allow_new_entries=True,\n",
    "    tune_new_entries=True,\n",
    "    seed=SEED,\n",
    "    directory=\"../hparam-tuning\",\n",
    "    project_name=\"cnn\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1c7ef3d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 3\n",
      "dropout (Float)\n",
      "{'default': 0.1, 'conditions': [], 'min_value': 0.1, 'max_value': 0.4, 'step': 0.1, 'sampling': None}\n",
      "dense-layer-units (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 128, 'step': 32, 'sampling': None}\n",
      "learning-rate (Choice)\n",
      "{'default': 0.0001, 'conditions': [], 'values': [0.0001, 0.0002, 0.00030000000000000003, 0.0004, 0.0005], 'ordered': True}\n"
     ]
    }
   ],
   "source": [
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "571221da",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_cohen_kappa\",\n",
    "    verbose=1,\n",
    "    patience=5,\n",
    "    mode=\"max\",\n",
    "    baseline=0.0,\n",
    "    restore_best_weights=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "301918fc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1 Complete [00h 05m 17s]\n",
      "val_cohen_kappa: 0.02504885196685791\n",
      "\n",
      "Best val_cohen_kappa So Far: 0.02504885196685791\n",
      "Total elapsed time: 00h 05m 17s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner.search(\n",
    "    trainset, epochs=1, validation_data=validationset, callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "588448c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The hyperparameter search is complete. \n",
      "\n",
      "\n",
      "Results\n",
      "=======\n",
      "|\n",
      "---- optimal dropout rate                                    : 0.4\n",
      "|\n",
      "---- optimal number of units in the densely-connected layer  : 128\n",
      "|\n",
      "---- optimal learning rate for the optimizer                 : 0.0002\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get the optimal hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(\n",
    "    f\"\"\"\n",
    "The hyperparameter search is complete. \\n\n",
    "\n",
    "Results\n",
    "=======\n",
    "|\n",
    "---- optimal dropout rate                                    : {best_hps.get('dropout')}\n",
    "|\n",
    "---- optimal number of units in the densely-connected layer  : {best_hps.get('dense-layer-units')}\n",
    "|\n",
    "---- optimal learning rate for the optimizer                 : {best_hps.get('learning-rate')}\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "90364155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " 1st-convolution (Conv2D)    (None, 224, 224, 16)      448       \n",
      "                                                                 \n",
      " 1st-batch-norm (BatchNormal  (None, 224, 224, 16)     64        \n",
      " ization)                                                        \n",
      "                                                                 \n",
      " 1st-max-pooling (MaxPooling  (None, 112, 112, 16)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " 1st-dropout (Dropout)       (None, 112, 112, 16)      0         \n",
      "                                                                 \n",
      " 2nd-convolution (Conv2D)    (None, 112, 112, 32)      4640      \n",
      "                                                                 \n",
      " 2nd-batch-norm (BatchNormal  (None, 112, 112, 32)     128       \n",
      " ization)                                                        \n",
      "                                                                 \n",
      " 2nd-max-pooling (MaxPooling  (None, 56, 56, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " 2nd-dropout (Dropout)       (None, 56, 56, 32)        0         \n",
      "                                                                 \n",
      " 3rd-convolution (Conv2D)    (None, 56, 56, 64)        18496     \n",
      "                                                                 \n",
      " 3rd-batch-norm (BatchNormal  (None, 56, 56, 64)       256       \n",
      " ization)                                                        \n",
      "                                                                 \n",
      " 3rd-max-pooling (MaxPooling  (None, 28, 28, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " 3rd-dropout (Dropout)       (None, 28, 28, 64)        0         \n",
      "                                                                 \n",
      " 4th-convolution (Conv2D)    (None, 28, 28, 128)       73856     \n",
      "                                                                 \n",
      " 4th-batch-norm (BatchNormal  (None, 28, 28, 128)      512       \n",
      " ization)                                                        \n",
      "                                                                 \n",
      " 4th-max-pooling (MaxPooling  (None, 14, 14, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " 4th-dropout (Dropout)       (None, 14, 14, 128)       0         \n",
      "                                                                 \n",
      " flatten-layer (Flatten)     (None, 25088)             0         \n",
      "                                                                 \n",
      " dense-layer (Dense)         (None, 128)               3211392   \n",
      "                                                                 \n",
      " output-layer (Dense)        (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,309,921\n",
      "Trainable params: 3,309,441\n",
      "Non-trainable params: 480\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
