{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a899787",
   "metadata": {},
   "source": [
    "## X-Ray Abnormality Detection with CNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7764e65",
   "metadata": {},
   "source": [
    "> Antonopoulos Ilias (p3352004) <br />\n",
    "> Ndoja Silva (p3352017) <br />\n",
    "> MSc Data Science AUEB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa71e65e",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "- [Data Loading](#Data-Loading)\n",
    "- [Exploratory Data Analysis](#Exploratory-Data-Analysis)\n",
    "- [Baseline Performance](#Baseline-Performance)\n",
    "- [Hyperparameter Tuning](#Hyperparameter-Tuning)\n",
    "- [Model Selection](#Model-Selection)\n",
    "- [Evaluation](#Evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6dbf09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: remove\n",
    "# !pip install scipy\n",
    "# !pip install git+https://github.com/keras-team/keras-tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fc7dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import itertools\n",
    "import os\n",
    "import pathlib\n",
    "import random\n",
    "import re\n",
    "from glob import glob\n",
    "\n",
    "import keras_tuner as kt\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from plotnine import *\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "pd.set_option(\"max_colwidth\", None)\n",
    "# from scipy import optimize  # TODO: remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d64d949",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6659fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 123456\n",
    "\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6c351a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa8b39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices(\"GPU\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9978aa80",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"data/augmented\"):  # to be able to inspect image augmentation\n",
    "    os.makedirs(\"data/augmented\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5346f99",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e69e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inspect_df(df: pd.DataFrame, n: int = 5) -> pd.DataFrame:\n",
    "    \"\"\"Helper method to easily inspect DataFrames.\"\"\"\n",
    "\n",
    "    print(f\"shape: {df.shape}\")\n",
    "\n",
    "    return df.head(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5819c5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DIR = \"data/MURA-v1.1/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d931da",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.choices(glob(os.path.join(DATASET_DIR, \"*\", \"*\", \"*\", \"*\", \"*.png\")), k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e99c8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_count = len(list(pathlib.Path(DATASET_DIR).glob(\"*/*/*/*/*.png\")))\n",
    "\n",
    "print(f\"Total PNG images found in dir <{DATASET_DIR}>: {image_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee568f1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_image_paths = pd.read_csv(\n",
    "    os.path.join(DATASET_DIR, \"train_image_paths.csv\"),\n",
    "    names=[\"image_path\"],\n",
    "    header=None,\n",
    "    index_col=False,\n",
    ")\n",
    "\n",
    "inspect_df(train_image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a69725",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_paths[\"image_path\"] = train_image_paths[\"image_path\"].map(\n",
    "    lambda x: os.path.join(\"data/\", x)\n",
    ")\n",
    "train_image_paths[\"study_type\"] = train_image_paths[\"image_path\"].map(\n",
    "    lambda x: x.split(\"/\")[3]\n",
    ")\n",
    "train_image_paths[\"patient\"] = train_image_paths[\"image_path\"].map(\n",
    "    lambda x: x.split(\"/\")[4]\n",
    ")\n",
    "train_image_paths[\"study\"] = train_image_paths[\"image_path\"].map(\n",
    "    lambda x: x.split(\"/\")[5]\n",
    ")\n",
    "train_image_paths[\"study_path\"] = train_image_paths[\"image_path\"].map(\n",
    "    lambda x: re.sub(r\"image\\d+.png\", \"\", x)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d073e76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "inspect_df(train_image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59cf2544",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_labeled_studies = pd.read_csv(\n",
    "    os.path.join(DATASET_DIR, \"train_labeled_studies.csv\"),\n",
    "    names=[\"study_path\", \"label\"],\n",
    "    header=None,\n",
    "    index_col=False,\n",
    ")\n",
    "\n",
    "inspect_df(train_labeled_studies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9a7f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labeled_studies[\"study_path\"] = train_labeled_studies[\"study_path\"].map(\n",
    "    lambda x: os.path.join(\"data/\", x)\n",
    ")\n",
    "train_labeled_studies[\"label\"] = train_labeled_studies[\"label\"].map(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408b169b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "inspect_df(train_labeled_studies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c49b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_trainset = pd.merge(\n",
    "    train_image_paths, train_labeled_studies, how=\"inner\", on=\"study_path\"\n",
    ")\n",
    "\n",
    "inspect_df(ref_trainset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41eafe23",
   "metadata": {},
   "source": [
    "#### Create a Tensorflow input pipeline for the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8637a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "training = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rotation_range=30,\n",
    "    brightness_range=None,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"constant\",\n",
    "    cval=0.0,\n",
    "    rescale=1.0 / 255,\n",
    "    validation_split=0.2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f38eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = training.flow_from_dataframe(\n",
    "    dataframe=ref_trainset,\n",
    "    x_col=\"image_path\",\n",
    "    y_col=\"label\",\n",
    "    target_size=(128, 128),\n",
    "    class_mode=\"binary\",\n",
    "    batch_size=32,\n",
    "    seed=SEED,\n",
    "    save_to_dir=\"data/augmented\",\n",
    "    subset=\"training\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3baff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "validationset = training.flow_from_dataframe(\n",
    "    dataframe=ref_trainset,\n",
    "    x_col=\"image_path\",\n",
    "    y_col=\"label\",\n",
    "    target_size=(128, 128),\n",
    "    class_mode=\"binary\",\n",
    "    batch_size=32,\n",
    "    seed=SEED,\n",
    "    save_to_dir=\"data/augmented\",\n",
    "    subset=\"validation\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6384ad36",
   "metadata": {},
   "source": [
    "#### Create a Tensorflow input pipeline for the testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530cb791",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_paths = pd.read_csv(\n",
    "    os.path.join(DATASET_DIR, \"valid_image_paths.csv\"),\n",
    "    names=[\"image_path\"],\n",
    "    header=None,\n",
    "    index_col=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c564c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_paths[\"image_path\"] = test_image_paths[\"image_path\"].map(\n",
    "    lambda x: os.path.join(\"data/\", x)\n",
    ")\n",
    "test_image_paths[\"study_type\"] = test_image_paths[\"image_path\"].map(\n",
    "    lambda x: x.split(\"/\")[3]\n",
    ")\n",
    "test_image_paths[\"patient\"] = test_image_paths[\"image_path\"].map(\n",
    "    lambda x: x.split(\"/\")[4]\n",
    ")\n",
    "test_image_paths[\"study\"] = test_image_paths[\"image_path\"].map(\n",
    "    lambda x: x.split(\"/\")[5]\n",
    ")\n",
    "test_image_paths[\"study_path\"] = test_image_paths[\"image_path\"].map(\n",
    "    lambda x: re.sub(r\"image\\d+.png\", \"\", x)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fa25e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labeled_studies = pd.read_csv(\n",
    "    os.path.join(DATASET_DIR, \"valid_labeled_studies.csv\"),\n",
    "    names=[\"study_path\", \"label\"],\n",
    "    header=None,\n",
    "    index_col=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b658d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labeled_studies[\"study_path\"] = test_labeled_studies[\"study_path\"].map(\n",
    "    lambda x: os.path.join(\"data/\", x)\n",
    ")\n",
    "test_labeled_studies[\"label\"] = test_labeled_studies[\"label\"].map(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28789518",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_testset = pd.merge(\n",
    "    test_image_paths, test_labeled_studies, how=\"inner\", on=\"study_path\"\n",
    ")\n",
    "\n",
    "inspect_df(ref_testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a83dfa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rotation_range=30,\n",
    "    brightness_range=None,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"constant\",\n",
    "    cval=0.0,\n",
    "    rescale=1.0 / 255,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c466ce62",
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = testing.flow_from_dataframe(\n",
    "    dataframe=ref_testset,\n",
    "    x_col=\"image_path\",\n",
    "    y_col=\"label\",\n",
    "    target_size=(128, 128),\n",
    "    class_mode=\"binary\",\n",
    "    batch_size=32,\n",
    "    seed=SEED,\n",
    "    save_to_dir=\"data/augmented\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4dce18",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa32020",
   "metadata": {},
   "source": [
    "Each study contains one or more views (images) and is labeled as either normal or abnormal.\n",
    "\n",
    "The training dataset consists of `13456` studies with a total of `36807` images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92ac2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "abnormal = train_labeled_studies[\"label\"] == \"1\"\n",
    "\n",
    "(\n",
    "    ggplot()\n",
    "    + geom_bar(mapping=aes(x=abnormal), colour=\"black\")\n",
    "    + labs(title=\"study is abnormal?\", x=\"\")\n",
    "    + coord_flip()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f11ff1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "(\n",
    "    ggplot(train_image_paths)\n",
    "    + geom_bar(aes(x=\"study_type\"), colour=\"black\")\n",
    "    + theme(axis_text_x=element_text(rotation=45, hjust=1))\n",
    "    + labs(x=\"\", y=\"count\", title=\"distribution of images per study type\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d182d1",
   "metadata": {},
   "source": [
    "### Baseline Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53dda1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_up(model_):\n",
    "    tf.keras.backend.clear_session()\n",
    "    del model_\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe4f685",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3a6125",
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "    tf.keras.metrics.TruePositives(name=\"tp\"),\n",
    "    tf.keras.metrics.FalsePositives(name=\"fp\"),\n",
    "    tf.keras.metrics.TrueNegatives(name=\"tn\"),\n",
    "    tf.keras.metrics.FalseNegatives(name=\"fn\"),\n",
    "    tf.keras.metrics.BinaryAccuracy(name=\"accuracy\"),\n",
    "    tf.keras.metrics.Precision(name=\"precision\"),\n",
    "    tf.keras.metrics.Recall(name=\"recall\"),\n",
    "    tf.keras.metrics.AUC(name=\"auc\"),\n",
    "    tf.keras.metrics.AUC(name=\"prc\", curve=\"PR\"),  # precision-recall curve\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571221da",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_prc\",\n",
    "    verbose=1,\n",
    "    patience=10,\n",
    "    mode=\"max\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d269acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(history):\n",
    "\n",
    "    plt.rcParams[\"figure.figsize\"] = (12, 10)\n",
    "    colors = plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"]\n",
    "    metrics = [\"loss\", \"prc\", \"precision\", \"recall\"]\n",
    "    for n, metric in enumerate(metrics):\n",
    "        name = metric.replace(\"_\", \" \").capitalize()\n",
    "        plt.subplot(2, 2, n + 1)\n",
    "        plt.plot(history.epoch, history.history[metric], color=colors[0], label=\"Train\")\n",
    "        plt.plot(\n",
    "            history.epoch,\n",
    "            history.history[\"val_\" + metric],\n",
    "            color=colors[0],\n",
    "            linestyle=\"--\",\n",
    "            label=\"Val\",\n",
    "        )\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(name)\n",
    "        if metric == \"loss\":\n",
    "            plt.ylim([0, plt.ylim()[1]])\n",
    "        elif metric == \"auc\":\n",
    "            plt.ylim([0.8, 1])\n",
    "        else:\n",
    "            plt.ylim([0, 1])\n",
    "\n",
    "        plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20cdbe13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(\n",
    "    cm, classes, normalize=False, title=\"Confusion matrix\", cmap=plt.cm.PuBuGn\n",
    "):\n",
    "\n",
    "    plt.style.use(\"default\")\n",
    "    plt.rcParams[\"figure.figsize\"] = [11, 9]\n",
    "    plt.imshow(cm, interpolation=\"nearest\", cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=90)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    thresh = cm.max() / 2.0\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(\n",
    "            j,\n",
    "            i,\n",
    "            cm[i, j],\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\",\n",
    "        )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel(\"True label\")\n",
    "    plt.xlabel(\"Predicted label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202355bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_cnn_model():\n",
    "    \"\"\"Creates a CNN architecture with sensible defaults.\"\"\"\n",
    "    model = tf.keras.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.Conv2D(\n",
    "                filters=64,\n",
    "                kernel_size=(3, 3),\n",
    "                strides=(1, 1),\n",
    "                padding=\"same\",\n",
    "                kernel_regularizer=\"l2\",\n",
    "                dilation_rate=(1, 1),\n",
    "                activation=\"relu\",\n",
    "                input_shape=(128, 128, 3),\n",
    "                name=\"1st-convolution\",\n",
    "            ),\n",
    "            tf.keras.layers.MaxPool2D(\n",
    "                pool_size=(2, 2), strides=(2, 2), padding=\"same\", name=\"1st-max-pooling\"\n",
    "            ),\n",
    "            tf.keras.layers.Dropout(\n",
    "                rate=0.2,\n",
    "                name=\"1st-dropout\",\n",
    "            ),\n",
    "            tf.keras.layers.Conv2D(\n",
    "                filters=32,\n",
    "                kernel_size=(3, 3),\n",
    "                strides=(1, 1),\n",
    "                padding=\"same\",\n",
    "                kernel_regularizer=\"l2\",\n",
    "                dilation_rate=(1, 1),\n",
    "                activation=\"relu\",\n",
    "                name=\"2nd-convolution\",\n",
    "            ),\n",
    "            tf.keras.layers.MaxPool2D(\n",
    "                pool_size=(2, 2), strides=(2, 2), padding=\"same\", name=\"2nd-max-pooling\"\n",
    "            ),\n",
    "            tf.keras.layers.Dropout(\n",
    "                rate=0.2,\n",
    "                name=\"2nd-dropout\",\n",
    "            ),\n",
    "            tf.keras.layers.Flatten(name=\"flatten-layer\"),\n",
    "            tf.keras.layers.Dense(\n",
    "                units=32,\n",
    "                kernel_regularizer=\"l2\",\n",
    "                activation=\"relu\",\n",
    "                name=\"dense-layer\",\n",
    "            ),\n",
    "            tf.keras.layers.Dense(units=1, activation=\"sigmoid\", name=\"output-layer\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "        loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "        metrics=METRICS,\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e68f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_cnn_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c19ad13",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97981226",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(\n",
    "    model,\n",
    "    to_file=\"static/cnn_baseline_model.png\",\n",
    "    show_shapes=True,\n",
    "    show_layer_names=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa319ec8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    trainset, epochs=100, validation_data=validationset, callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4fda3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b3e659",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metrics = model.evaluate(testset, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09883d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = metrics.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f9b657",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"test loss: {loss}\")\n",
    "for metric, score in zip(METRICS, metrics):\n",
    "\n",
    "    print(f\"{metric.name}: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db100db",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = model.predict(testset, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15167cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_classes = np.argmax(Y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91559084",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_mtx = confusion_matrix(testset.labels, Y_pred_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298a5c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(\n",
    "    confusion_mtx,\n",
    "    classes=[\"normal\", \"abnormal\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9491c46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_up(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18fb2573",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8008f933",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model_builder(hp):\n",
    "    \"\"\"Creates a HyperModel instance (or callable that takes hyperparameters and returns a Model instance).\"\"\"\n",
    "    model = tf.keras.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.Conv2D(\n",
    "                filters=hp.Int(\"1st-filter\", min_value=32, max_value=128, step=16),\n",
    "                kernel_size=(3, 3),\n",
    "                strides=(1, 1),\n",
    "                padding=\"same\",\n",
    "                kernel_regularizer=\"l2\",\n",
    "                dilation_rate=(1, 1),\n",
    "                activation=\"relu\",\n",
    "                input_shape=(128, 128, 3),\n",
    "                name=\"1st-convolution\",\n",
    "            ),\n",
    "            tf.keras.layers.MaxPool2D(\n",
    "                pool_size=(2, 2), strides=(2, 2), padding=\"same\", name=\"1st-max-pooling\"\n",
    "            ),\n",
    "            tf.keras.layers.Dropout(\n",
    "                rate=hp.Float(\"1st-dropout\", min_value=0.0, max_value=0.4, step=0.1),\n",
    "                name=\"1st-dropout\",\n",
    "            ),\n",
    "            tf.keras.layers.Conv2D(\n",
    "                filters=hp.Int(\"2nd-filter\", min_value=32, max_value=64, step=16),\n",
    "                kernel_size=(3, 3),\n",
    "                strides=(1, 1),\n",
    "                padding=\"same\",\n",
    "                kernel_regularizer=\"l2\",\n",
    "                dilation_rate=(1, 1),\n",
    "                activation=\"relu\",\n",
    "                name=\"2nd-convolution\",\n",
    "            ),\n",
    "            tf.keras.layers.MaxPool2D(\n",
    "                pool_size=(2, 2), strides=(2, 2), padding=\"same\", name=\"2nd-max-pooling\"\n",
    "            ),\n",
    "            tf.keras.layers.Dropout(\n",
    "                rate=hp.Float(\"2nd-dropout\", min_value=0.0, max_value=0.4, step=0.1),\n",
    "                name=\"2nd-dropout\",\n",
    "            ),\n",
    "            tf.keras.layers.Flatten(name=\"flatten-layer\"),\n",
    "            tf.keras.layers.Dense(\n",
    "                units=hp.Int(\"dense-layer-units\", min_value=32, max_value=128, step=16),\n",
    "                kernel_regularizer=\"l2\",\n",
    "                activation=\"relu\",\n",
    "                name=\"dense-layer\",\n",
    "            ),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.Dense(units=1, activation=\"sigmoid\", name=\"output-layer\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(\n",
    "            learning_rate=hp.Choice(\n",
    "                \"learning-rate\", values=[1e-3, 1e-4, 2 * 1e-4, 4 * 1e-4]\n",
    "            )\n",
    "        ),\n",
    "        loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "        metrics=METRICS,\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7c2a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Li, Lisha, and Kevin Jamieson.\n",
    "# \"Hyperband: A Novel Bandit-Based Approach to Hyperparameter Optimization.\"\n",
    "# Journal of Machine Learning Research 18 (2018): 1-52.\n",
    "# https://jmlr.org/papers/v18/16-558.html\n",
    "tuner = kt.Hyperband(\n",
    "    cnn_model_builder,\n",
    "    objective=kt.Objective(\"val_prc\", direction=\"max\"),\n",
    "    max_epochs=50,  # the maximum number of epochs to train one model\n",
    "    seed=SEED,\n",
    "    directory=\"hparam-tuning\",\n",
    "    project_name=\"cnn\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa4fdd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581ad518",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tuner.search(\n",
    "    trainset,\n",
    "    validation_data=validationset,\n",
    "    epochs=50,\n",
    "    shuffle=True,\n",
    "    verbose=1,\n",
    "    callbacks=[early_stopping],\n",
    ")\n",
    "\n",
    "# get the optimal hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(\n",
    "    f\"\"\"\n",
    "The hyperparameter search is complete. \\n\n",
    "\n",
    "Results\n",
    "=======\n",
    "|\n",
    "---- optimal number of output filters in the 1st convolution : {best_hps.get('1st-filter')}\n",
    "|\n",
    "---- optimal first dropout rate                              : {best_hps.get('1st-dropout')}\n",
    "|\n",
    "---- optimal number of output filters in the 2nd convolution : {best_hps.get('2nd-filter')}\n",
    "|\n",
    "---- optimal second dropout rate                             : {best_hps.get('2nd-dropout')}\n",
    "|\n",
    "---- optimal number of units in the densely-connected layer  : {best_hps.get('dense-layer-units')}\n",
    "|\n",
    "---- optimal learning rate for the optimizer                 : {best_hps.get('learning-rate')}\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ea84e3",
   "metadata": {},
   "source": [
    "### Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68dc2eaf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e954e788",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(\n",
    "    model, to_file=\"static/cnn_best_model.png\", show_shapes=True, show_layer_names=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52495aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_up(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fea15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the model with the optimal hyperparameters and train it on the data for 50 epochs\n",
    "hypermodel = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "history = hypermodel.fit(\n",
    "    trainset, epochs=50, validation_data=validationset, callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4618355",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep best epoch\n",
    "val_prc_per_epoch = history.history[\"val_prc\"]\n",
    "best_epoch = val_prc_per_epoch.index(max(val_prc_per_epoch)) + 1\n",
    "print(\"Best epoch: %d\" % (best_epoch,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411753cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_up(hypermodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a11ca7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the model with the optimal hyperparameters and train it on the data for 50 epochs\n",
    "hypermodel = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "history = hypermodel.fit(\n",
    "    trainset,\n",
    "    epochs=best_epoch,\n",
    "    validation_data=validationset,\n",
    "    callbacks=[early_stopping],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e297f13",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3b0059",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = hypermodel.evaluate(testset, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6ff76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = metrics.pop(0)\n",
    "\n",
    "print(f\"test loss: {loss}\")\n",
    "for metric, score in zip(METRICS, metrics):\n",
    "\n",
    "    print(f\"{metric.name}: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f8e85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = model.predict(testset, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758a768c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_classes = np.argmax(Y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc11e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_mtx = confusion_matrix(testset.labels, Y_pred_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f455be",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(\n",
    "    confusion_mtx,\n",
    "    classes=[\"normal\", \"abnormal\"],\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
